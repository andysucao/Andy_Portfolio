<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Project 2: Predicitng Customer Churn for a Mobile Phone Carrier | Andy Cao</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.116.1">
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://andysucao.github.io/Andy_Portfolio/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Project 2: Predicitng Customer Churn for a Mobile Phone Carrier" />
<meta property="og:description" content="Develop machine learning models to predict customer churn using Logistic Regression, Decision Tree, Ensemble methods (Random Forest, Adaboost, GBDT), and Neural Network" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://andysucao.github.io/Andy_Portfolio/post/project-2/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-08-20T06:01:00-04:00" />
<meta property="article:modified_time" content="2023-08-20T06:01:00-04:00" />
<meta itemprop="name" content="Project 2: Predicitng Customer Churn for a Mobile Phone Carrier">
<meta itemprop="description" content="Develop machine learning models to predict customer churn using Logistic Regression, Decision Tree, Ensemble methods (Random Forest, Adaboost, GBDT), and Neural Network"><meta itemprop="datePublished" content="2023-08-20T06:01:00-04:00" />
<meta itemprop="dateModified" content="2023-08-20T06:01:00-04:00" />
<meta itemprop="wordCount" content="1474">
<meta itemprop="keywords" content="Machine Learning,Logistic Regression," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Project 2: Predicitng Customer Churn for a Mobile Phone Carrier"/>
<meta name="twitter:description" content="Develop machine learning models to predict customer churn using Logistic Regression, Decision Tree, Ensemble methods (Random Forest, Adaboost, GBDT), and Neural Network"/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://andysucao.github.io/Andy_Portfolio/images/projects-2-1.jpg');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://andysucao.github.io/Andy_Portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      Andy Cao
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/skills/" title="Useful skills page">
              Useful skills
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/cao/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/andysucao" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Project 2: Predicitng Customer Churn for a Mobile Phone Carrier</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Develop machine learning models to predict customer churn using Logistic Regression, Decision Tree, Ensemble methods (Random Forest, Adaboost, GBDT), and Neural Network
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://andysucao.github.io/Andy_Portfolio/post/project-2/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://andysucao.github.io/Andy_Portfolio/post/project-2/&amp;text=Project%202:%20Predicitng%20Customer%20Churn%20for%20a%20Mobile%20Phone%20Carrier" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://andysucao.github.io/Andy_Portfolio/post/project-2/&amp;title=Project%202:%20Predicitng%20Customer%20Churn%20for%20a%20Mobile%20Phone%20Carrier" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Project 2: Predicitng Customer Churn for a Mobile Phone Carrier</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-08-20T06:01:00-04:00">August 20, 2023</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h2 id="1-overview">1. Overview</h2>
<p>In this project, we will build a series of models to predict the probability of Customer Churn for a Mobile Phone Carrier.</p>
<p>In the first part, we will conduct Exploratory Data Analysis (EDA). Here the Synthetic Minority Oversampling Technique (SMOTE) method is employed to address the imbalanced classification problem. Then we will develop customer churn prediction models based on (1) Logistic Regression, (2) Decision Tree, (3) Random Forest, (4) AdaBoost, (5) Gradient Boosting Decision Trees (GBDT), and (6) Neural Network. With model hyperparameters optimized by <code>GridSearchCV</code> from <code>sklearn</code> package, the performance of each model is pretty good (measured by ROC-AUC, please see the table below).</p>
<hr>
<table>
<thead>
<tr>
<th style="text-align:left">Model</th>
<th style="text-align:left">ROC-AUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Logistic Regression</td>
<td style="text-align:left">0.9219</td>
</tr>
<tr>
<td style="text-align:left">Decision Tree</td>
<td style="text-align:left">0.9138</td>
</tr>
<tr>
<td style="text-align:left">Random Forest</td>
<td style="text-align:left">0.9277</td>
</tr>
<tr>
<td style="text-align:left">Adaboost</td>
<td style="text-align:left">0.9373</td>
</tr>
<tr>
<td style="text-align:left">Gradient Boosting Decision Trees (GBDT)</td>
<td style="text-align:left">0.9260</td>
</tr>
<tr>
<td style="text-align:left">Neural Network</td>
<td style="text-align:left">0.9251</td>
</tr>
</tbody>
</table>
<hr>
<p>The Python Notebook containing the complete model development process and the data used in this project can be found at <a href="https://drive.google.com/drive/folders/1huLD3Pm9pZIhcqHSl4XCoRZgQIxQ1uPj?usp=sharing">Google Drive</a>.</p>
<p>           
           </p>
<h2 id="2-exploratory-data-analysis-eda">2. Exploratory Data Analysis (EDA)</h2>
<p>The dataset <a href="https://drive.google.com/file/d/15WeDybOcZH7_Z9_Phv20rgChlAXXu1Au/view?usp=sharing">Google Drive</a> of Customer Churn for a Mobile Phone Carrier is from <em>SAS Financial Data Mining and Modeling</em> (<a href="https://shuyuan.hzmedia.com.cn/ebookdtl?id=11118733">link</a>). Since the computation was performed on Google Colab platform, we will first mount the Google Drive and load some useful packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> google.colab <span style="color:#f92672">import</span> drive
</span></span><span style="display:flex;"><span>drive<span style="color:#f92672">.</span>mount(<span style="color:#e6db74">&#39;/content/drive&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> stats
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> statsmodels.api <span style="color:#66d9ef">as</span> sm
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> statsmodels.formula.api <span style="color:#66d9ef">as</span> smf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.metrics <span style="color:#66d9ef">as</span> metrics
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> statsmodels.formula.api <span style="color:#f92672">import</span> ols
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> StandardScaler
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> linear_model
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> l1_min_c
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> cross_val_score
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> roc_auc_score
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> GridSearchCV
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.neural_network <span style="color:#f92672">import</span> MLPClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pylab <span style="color:#f92672">import</span> mpl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pydotplus
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> IPython.display <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.tree <span style="color:#66d9ef">as</span> tree
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> imblearn.over_sampling <span style="color:#f92672">import</span> ADASYN
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> imblearn.over_sampling <span style="color:#f92672">import</span> SMOTE
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> imblearn.combine <span style="color:#f92672">import</span> SMOTETomek
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> MinMaxScaler
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.ensemble <span style="color:#66d9ef">as</span> ensemble
</span></span><span style="display:flex;"><span>get_ipython()<span style="color:#f92672">.</span>run_line_magic(<span style="color:#e6db74">&#39;matplotlib&#39;</span>, <span style="color:#e6db74">&#39;inline&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pd<span style="color:#f92672">.</span>set_option(<span style="color:#e6db74">&#39;display.max_columns&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> warnings
</span></span><span style="display:flex;"><span>warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#39;ignore&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># warnings.filterwarnings(&#39;default&#39;)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># pd.options.display.max_rows = 4000</span>
</span></span></code></pre></div><p>By copying the dataset from Google Drive to the working directory and load it (see command and results below), we can see that the dataset is composed of 2484 rows and 19 variables. Each variable is examined carefully in the <a href="https://colab.research.google.com/drive/18STLpbYJCAAv135uwNc3Z9s8yAmy3u1A?usp=sharing">full script</a>, here we will just examine one representative independent variable, <code>duration</code>, as well as the dependent variable <code>churn</code>.</p>
<p>           </p>
<h3 id="21-duration">2.1. Duration</h3>
<p>Variable &lsquo;duration&rsquo; indicates the length of a customer relationship with the company. From the plots below, we can see that the duration for churned customers is much shorter, and this observation is also consistent with the F-test results that variable <code>churn</code> has a very large F value of 624.9 and very small p value of 3.36e-123.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>ax1 <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>ax2 <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>kdeplot(data<span style="color:#f92672">=</span>tel, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;duration&#39;</span>, hue<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;churn&#39;</span>, fill<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, ax<span style="color:#f92672">=</span>ax1)
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>boxplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;churn&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;duration&#39;</span>, data <span style="color:#f92672">=</span> tel, showmeans<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, ax<span style="color:#f92672">=</span>ax2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tel<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;churn&#39;</span>)[[<span style="color:#e6db74">&#39;duration&#39;</span>]]<span style="color:#f92672">.</span>describe()<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>sm<span style="color:#f92672">.</span>stats<span style="color:#f92672">.</span>anova_lm(ols(<span style="color:#e6db74">&#39;duration ~ C(churn)&#39;</span>,data<span style="color:#f92672">=</span>tel)<span style="color:#f92672">.</span>fit())
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-2.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-2.png" alt=""> </a></p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">df</th>
<th style="text-align:left">sum_sq      </th>
<th style="text-align:left">mean_sq      </th>
<th style="text-align:left">F</th>
<th style="text-align:left">PR(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">C(churn)</td>
<td style="text-align:left">1</td>
<td style="text-align:left">73698</td>
<td style="text-align:left">73698</td>
<td style="text-align:left">624.9      </td>
<td style="text-align:left">3.36e-123</td>
</tr>
<tr>
<td style="text-align:left">Residual      </td>
<td style="text-align:left">2482      </td>
<td style="text-align:left">292727</td>
<td style="text-align:left">118</td>
<td style="text-align:left">NaN</td>
<td style="text-align:left">NaN</td>
</tr>
</tbody>
</table>
<p>           </p>
<h3 id="22-churn">2.2. Churn</h3>
<p>The dependent variable <code>churn</code> is examined below. In the first part of the code block, we examined itd distribution and found its distribution unbalanced. Then we split the dataset into training set and test set, and apply the Synthetic Minority Oversampling Technique (SMOTE) to the training set. The plots below shows the distribution of churn before (left) and after (right) applying SMOTE method. In the next section, we will use the rebalanced training set to develop model and the original test set to evaluate the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Y - churn, 0 - False, 1 - True</span>
</span></span><span style="display:flex;"><span>tel<span style="color:#f92672">.</span>churn<span style="color:#f92672">.</span>value_counts()<span style="color:#f92672">.</span>plot(kind <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;pie&#39;</span>,autopct<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%.1f%%</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Split the dataset into train set and test set</span>
</span></span><span style="display:flex;"><span>train <span style="color:#f92672">=</span> tel<span style="color:#f92672">.</span>sample(frac <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.8</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">76</span>)<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> tel[<span style="color:#f92672">~</span>tel<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>isin(train<span style="color:#f92672">.</span>index)]<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39; Size of training set: </span><span style="color:#e6db74">%i</span><span style="color:#e6db74"> </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Size of test set: </span><span style="color:#e6db74">%i</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>(len(train), len(test)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Employ Synthetic Minority Oversampling Technique (SMOTE) for Imbalanced Classification</span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>X_train<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;churn&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>y_train <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>churn<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>X_test<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;churn&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>y_test <span style="color:#f92672">=</span> test<span style="color:#f92672">.</span>churn<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kos <span style="color:#f92672">=</span> SMOTE(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>X_kos, y_kos <span style="color:#f92672">=</span> kos<span style="color:#f92672">.</span>fit_resample(X_train, y_train)
</span></span><span style="display:flex;"><span>y_kos<span style="color:#f92672">.</span>value_counts()<span style="color:#f92672">.</span>plot(kind <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;pie&#39;</span>,autopct<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%.1f%%</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-3.jpg"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-3.jpg" alt=""> </a></p>
<h2 id="3-developing-customer-churn-prediction-model">3. Developing customer churn prediction model</h2>
<p>This section is composed of four parts. In the first part, we will build model based on the Logistic Regression algorithm. In the second part, we will build model using Decision Tree. Then in part three Ensemble methods (i.e., Random Forest, AdaBoost, and GBDT) will be introduced. Finally in the fourth part, we will build a Neural Network-based model.</p>
<p>           </p>
<h3 id="31-logistic-regression">3.1. Logistic Regression</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scaler <span style="color:#f92672">=</span> StandardScaler()
</span></span><span style="display:flex;"><span>X_kos <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>fit_transform(X_kos)
</span></span><span style="display:flex;"><span>X_test <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cs <span style="color:#f92672">=</span> l1_min_c(X_kos, y_kos, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;log&#39;</span>) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>logspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">7</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Computing regularization path ...&#34;</span>)
</span></span><span style="display:flex;"><span>start <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
</span></span><span style="display:flex;"><span>clf <span style="color:#f92672">=</span> linear_model<span style="color:#f92672">.</span>LogisticRegression(C<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l1&#39;</span>, tol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-6</span>, max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;liblinear&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>coefs_ <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> cs:
</span></span><span style="display:flex;"><span>    clf<span style="color:#f92672">.</span>set_params(C<span style="color:#f92672">=</span>c)
</span></span><span style="display:flex;"><span>    clf<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>    coefs_<span style="color:#f92672">.</span>append(clf<span style="color:#f92672">.</span>coef_<span style="color:#f92672">.</span>ravel()<span style="color:#f92672">.</span>copy())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39; &#39;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;This took &#34;</span>, datetime<span style="color:#f92672">.</span>now() <span style="color:#f92672">-</span> start)
</span></span><span style="display:flex;"><span>coefs_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(coefs_)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>log10(cs), coefs_)
</span></span><span style="display:flex;"><span>ymin, ymax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>ylim()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;log(C)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Coefficients&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Logistic Regression Path&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;tight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cs <span style="color:#f92672">=</span> l1_min_c(X_kos, y_kos, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;log&#39;</span>) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>logspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">7</span>)
</span></span><span style="display:flex;"><span>k_scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>clf <span style="color:#f92672">=</span> linear_model<span style="color:#f92672">.</span>LogisticRegression(penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l1&#39;</span>)
</span></span><span style="display:flex;"><span>clf <span style="color:#f92672">=</span> linear_model<span style="color:#f92672">.</span>LogisticRegression(penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l1&#39;</span>, tol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>, max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;liblinear&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#http://scikit-learn.org/stable/modules/model_evaluation.html</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> cs:
</span></span><span style="display:flex;"><span>    clf<span style="color:#f92672">.</span>set_params(C<span style="color:#f92672">=</span>c)
</span></span><span style="display:flex;"><span>    scores <span style="color:#f92672">=</span> cross_val_score(clf, X_kos, y_kos, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span>)
</span></span><span style="display:flex;"><span>    k_scores<span style="color:#f92672">.</span>append([c,scores<span style="color:#f92672">.</span>mean(),scores<span style="color:#f92672">.</span>std()])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data<span style="color:#f92672">=</span>pd<span style="color:#f92672">.</span>DataFrame(k_scores) <span style="color:#75715e">#convert dict to dataframe</span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure()
</span></span><span style="display:flex;"><span>ax1 <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>log10(data[<span style="color:#ae81ff">0</span>]), data[<span style="color:#ae81ff">1</span>],<span style="color:#e6db74">&#39;b&#39;</span>)
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Mean ROC (Blue)&#39;</span>)
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;log10(cs)&#39;</span>)
</span></span><span style="display:flex;"><span>ax2 <span style="color:#f92672">=</span> ax1<span style="color:#f92672">.</span>twinx()
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>log10(data[<span style="color:#ae81ff">0</span>]), data[<span style="color:#ae81ff">2</span>],<span style="color:#e6db74">&#39;r&#39;</span>)
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Std ROC Index (Red)&#39;</span>)
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>axline([<span style="color:#f92672">-</span><span style="color:#ae81ff">1.1</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#f92672">-</span><span style="color:#ae81ff">1.1</span>, <span style="color:#ae81ff">0.04</span>])
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-4b.jpg"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-4b.jpg" alt=""></a></p>
<p>The code and plots above shows the development of a multivariate logistic regression with L1 regularization. We compute the regularization path and visualize the mean and standard derivation of ROC vs inverse of regularization strength C. The figure shows that optimal value of C should be near exp(-1.1).</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-5.jpg"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-5.jpg" alt=""></a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>clf <span style="color:#f92672">=</span> linear_model<span style="color:#f92672">.</span>LogisticRegression(C<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span><span style="color:#ae81ff">1.1</span>), penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l1&#39;</span>,max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;liblinear&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>clf<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y_kos_pred <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(X_kos)
</span></span><span style="display:flex;"><span>y_kos_proba <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict_proba(X_kos)[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>y_test_pred <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>y_test_proba <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict_proba(X_test)[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;confusion_matrix&#39;</span>)
</span></span><span style="display:flex;"><span>print(metrics<span style="color:#f92672">.</span>confusion_matrix(y_test, y_test_pred))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;classification_report&#39;</span>)
</span></span><span style="display:flex;"><span>print(metrics<span style="color:#f92672">.</span>classification_report(y_test, y_test_pred))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fpr_train, tpr_train, th_train <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>roc_curve(y_kos, y_kos_proba)
</span></span><span style="display:flex;"><span>fpr_test, tpr_test, th_test <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>roc_curve(y_test, y_test_proba)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>[<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">6</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(fpr_train, tpr_train, <span style="color:#e6db74">&#39;r-&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train_data&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(fpr_test, tpr_test, <span style="color:#e6db74">&#39;b--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;test_data&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;ROC curve&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axline([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlim([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.02</span>, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1.02</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;FPR&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;TPR&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test[<span style="color:#e6db74">&#39;prediction&#39;</span>] <span style="color:#f92672">=</span> (y_test_proba <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;int&#39;</span>)
</span></span><span style="display:flex;"><span>acc <span style="color:#f92672">=</span> sum(test[<span style="color:#e6db74">&#39;prediction&#39;</span>] <span style="color:#f92672">==</span> test[<span style="color:#e6db74">&#39;churn&#39;</span>]) <span style="color:#f92672">/</span>float(len(test))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;The accurancy is </span><span style="color:#e6db74">%.4f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>acc)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;AUC = </span><span style="color:#e6db74">%.4f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>metrics<span style="color:#f92672">.</span>auc(fpr_test, tpr_test))
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-6.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-6.png" alt=""> </a></p>
<p>Then we can use the code above to generate model predictions and plotting the corresponding ROC curve. From ROC curve, we can see that for both the training set (with SMOTE) and test set (without SMOTE), the Logistic Regression model gives very good result, and this observation is further confirmed by AUC = 0.9219.</p>
<p>           </p>
<h3 id="32-decision-tree">3.2. Decision Tree</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;criterion&#39;</span>:[<span style="color:#e6db74">&#39;entropy&#39;</span>,<span style="color:#e6db74">&#39;gini&#39;</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;max_depth&#39;</span>:[<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">16</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;min_samples_split&#39;</span>:[<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">140</span>, <span style="color:#ae81ff">160</span>]
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dtclf <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>DecisionTreeClassifier(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">92</span>)
</span></span><span style="display:flex;"><span>clfcv <span style="color:#f92672">=</span> GridSearchCV(dtclf, param_grid<span style="color:#f92672">=</span>param_grid, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span> ,cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>clfcv<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dtclf <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>DecisionTreeClassifier(criterion<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gini&#39;</span>, max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, min_samples_split<span style="color:#f92672">=</span><span style="color:#ae81ff">140</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">92</span>)
</span></span><span style="display:flex;"><span>dtclf<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dot_data <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>export_graphviz(
</span></span><span style="display:flex;"><span>    dtclf,
</span></span><span style="display:flex;"><span>    out_file<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    feature_names<span style="color:#f92672">=</span>X_train<span style="color:#f92672">.</span>columns,
</span></span><span style="display:flex;"><span>    max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    class_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;0&#39;</span>,<span style="color:#e6db74">&#39;1&#39;</span>],
</span></span><span style="display:flex;"><span>    filled<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>graph <span style="color:#f92672">=</span> pydotplus<span style="color:#f92672">.</span>graph_from_dot_data(dot_data)
</span></span><span style="display:flex;"><span>Image(graph<span style="color:#f92672">.</span>create_png())
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-7.jpg"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-7.jpg" alt=""></a></p>
<p>The decision tree based model is shown in the code and figure above. From the visualization of the tree on the left plot, we can see that variable <code>duration</code> is indeed very important for predicting the customer churn. The model has a pretty nice ROC curve and its AUC is quite high too (i.e., 0.9138).</p>
<p>           </p>
<h3 id="33-ensemble-methods">3.3. Ensemble methods</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Random Forest</span>
</span></span><span style="display:flex;"><span>param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;max_depth&#39;</span>:[<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">1000</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;max_features&#39;</span>:[<span style="color:#ae81ff">0.001</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.1</span>], <span style="color:#75715e">#number of features to consider when looking for the best split</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;min_samples_split&#39;</span>:[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;n_estimators&#39;</span>:[<span style="color:#ae81ff">2000</span>, <span style="color:#ae81ff">4000</span>, <span style="color:#ae81ff">8000</span>] <span style="color:#75715e">#number of trees in the forest</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>rfc <span style="color:#f92672">=</span> ensemble<span style="color:#f92672">.</span>RandomForestClassifier()
</span></span><span style="display:flex;"><span>rfccv <span style="color:#f92672">=</span> GridSearchCV(estimator<span style="color:#f92672">=</span>rfc, param_grid<span style="color:#f92672">=</span>param_grid, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>rfccv<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Adaboost</span>
</span></span><span style="display:flex;"><span>param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;learning_rate&#39;</span>:[<span style="color:#ae81ff">0.3</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;n_estimators&#39;</span>:[<span style="color:#ae81ff">200</span>, <span style="color:#ae81ff">400</span>, <span style="color:#ae81ff">800</span>] <span style="color:#75715e">#number of trees</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>abc <span style="color:#f92672">=</span> ensemble<span style="color:#f92672">.</span>AdaBoostClassifier(algorithm<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SAMME&#39;</span>)
</span></span><span style="display:flex;"><span>abccv <span style="color:#f92672">=</span> GridSearchCV(estimator<span style="color:#f92672">=</span>abc, param_grid<span style="color:#f92672">=</span>param_grid, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>abccv<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Gradient Boosting Decision Trees (GBDT)</span>
</span></span><span style="display:flex;"><span>param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;learning_rate&#39;</span>:[<span style="color:#ae81ff">0.4</span>, <span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.2</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;max_depth&#39;</span>:[<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">15</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;n_estimators&#39;</span>:[<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">70</span>],
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gbc <span style="color:#f92672">=</span> ensemble<span style="color:#f92672">.</span>GradientBoostingClassifier(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>gbccv <span style="color:#f92672">=</span> GridSearchCV(estimator<span style="color:#f92672">=</span>gbc, param_grid<span style="color:#f92672">=</span>param_grid, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>gbccv<span style="color:#f92672">.</span>fit(X_kos, y_kos)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-8.jpg"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-8.jpg" alt=""></a></p>
<p>Three popular ensemble methods (i.e., Random Forest, AdaBoost, GBDT) are also applied to develop customer churn prediction models. Part of the code are shown above, together with their ROC curves. As we expected, all three method have very good ROC performance, and their AUC values are 0.9277 (Random Forest), 0.9373 (AdaBoost), 0.9260 (GBDT).</p>
<p>           </p>
<h3 id="34-neural-network">3.4. Neural Network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Standardize features</span>
</span></span><span style="display:flex;"><span>scaler <span style="color:#f92672">=</span> StandardScaler()
</span></span><span style="display:flex;"><span>X_kos_scaled <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>fit_transform(X_kos)
</span></span><span style="display:flex;"><span>X_test_scaled <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>param_grid<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;alpha&#39;</span>:[<span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>],
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;hidden_layer_sizes&#39;</span>:[(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">100</span>), (<span style="color:#ae81ff">200</span>,<span style="color:#ae81ff">200</span>), (<span style="color:#ae81ff">300</span>,<span style="color:#ae81ff">300</span>), (<span style="color:#ae81ff">400</span>,<span style="color:#ae81ff">400</span>)],
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mlp<span style="color:#f92672">=</span>MLPClassifier()
</span></span><span style="display:flex;"><span>gcv<span style="color:#f92672">=</span>GridSearchCV(estimator<span style="color:#f92672">=</span>mlp,param_grid<span style="color:#f92672">=</span>param_grid, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;roc_auc&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>gcv<span style="color:#f92672">.</span>fit(X_kos_scaled,y_kos)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-2-9.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-2-9.png" alt=""></a></p>
<p>Finally, we use the <code>MLPClassifier</code> module from <code>sklearn</code> to develop a very simple neural network for customer churn prediction. From the ROC curve shown above, we can see that the model also gives very good results, and the corresponding AUC is 0.9251.</p>
<p>           
           </p>
<h2 id="4-conclusions">4. Conclusions</h2>
<p>In this work, I have developed a series of models to predict customer churn for a mobile phone carrier. Among all the methods I tried, I would recommend AdaBoost if model interpretability is not required, because it is fast, robust, and very accurate. On the other hand, if &ldquo;black box&rdquo; model is not acceptable, then I would recommend Multivariate logistic regression with L1 regularization, because it is explainable and with careful hyperparameter tuning, very accurate prediction too.</p>
<ul class="pa0">
  
   <li class="list">
     <a href="https://andysucao.github.io/Andy_Portfolio/tags/machine-learning" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Machine Learning</a>
   </li>
  
   <li class="list">
     <a href="https://andysucao.github.io/Andy_Portfolio/tags/logistic-regression" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Logistic Regression</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://andysucao.github.io/Andy_Portfolio/post/project-1/">Project 1: Predict Real Estate Prices in Beijing</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://andysucao.github.io/Andy_Portfolio/" >
    &copy;  Andy Cao 2023 
  </a>
    <div>







<a href="https://www.linkedin.com/in/cao/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/andysucao" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>






</div>
  </div>
</footer>

    

  <script src="https://andysucao.github.io/Andy_Portfolio/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
