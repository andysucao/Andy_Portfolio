<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Project 3: Understanding Ridesharing Demands in New York City | Andy Cao</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.122.0">
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://andysucao.github.io/Andy_Portfolio/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Project 3: Understanding Ridesharing Demands in New York City" />
<meta property="og:description" content="Develop machine learning models to predict ridesharing demand in New York City using Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://andysucao.github.io/Andy_Portfolio/post/project-3/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-08-20T06:02:00-04:00" />
<meta property="article:modified_time" content="2023-08-20T06:02:00-04:00" />

<meta itemprop="name" content="Project 3: Understanding Ridesharing Demands in New York City">
<meta itemprop="description" content="Develop machine learning models to predict ridesharing demand in New York City using Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN)."><meta itemprop="datePublished" content="2023-08-20T06:02:00-04:00" />
<meta itemprop="dateModified" content="2023-08-20T06:02:00-04:00" />
<meta itemprop="wordCount" content="5183">
<meta itemprop="keywords" content="Machine Learning,Time Series Analysis," /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Project 3: Understanding Ridesharing Demands in New York City"/>
<meta name="twitter:description" content="Develop machine learning models to predict ridesharing demand in New York City using Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN)."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://andysucao.github.io/Andy_Portfolio/images/projects-3-1.jpg');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://andysucao.github.io/Andy_Portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      Andy Cao
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://andysucao.github.io/Andy_Portfolio/skills/" title="Useful skills page">
              Useful skills
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/cao/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/andysucao" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Project 3: Understanding Ridesharing Demands in New York City</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Develop machine learning models to predict ridesharing demand in New York City using Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN).
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://andysucao.github.io/Andy_Portfolio/post/project-3/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://andysucao.github.io/Andy_Portfolio/post/project-3/&amp;text=Project%203:%20Understanding%20Ridesharing%20Demands%20in%20New%20York%20City" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://andysucao.github.io/Andy_Portfolio/post/project-3/&amp;title=Project%203:%20Understanding%20Ridesharing%20Demands%20in%20New%20York%20City" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Project 3: Understanding Ridesharing Demands in New York City</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-08-20T06:02:00-04:00">August 20, 2023</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h2 id="1-overview">1. Overview</h2>
<p>In this project, we will focus on New York City&rsquo;s Ridesharing Trips Data Set and try to answer three interesting questions:</p>
<p>(1) How do the residents of New York City use Ridesharing?</p>
<p>(2) What usage patterns can we see?</p>
<p>(3) Can we predict usage?</p>
<p>To answer these questions, first we will clean up the trip data and integrate them with weather data and taxi zone geodata. Then we will conduct Exploratory Data Analysis (EDA) and Statistical Tests to find Temporal and Spatial Patterns, as well as weather effects and tipping behaviors. After that, we will develop a clustering model to gain a better understanding of how ridesharing is being
used. Finally we will develop four machine learning models to predict rideshare utilization, including Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN).</p>
<p>The Python Notebook containing the complete model development process and the data used in this project can be found at <a href="https://drive.google.com/drive/folders/1xXM1NlsId8nJb38ftkPvg6-UEw0_Tr2y?usp=sharing">Google Drive</a>.</p>
<p>           
           </p>
<h2 id="2-data-cleaning-wrangling-and-enhancement">2. Data cleaning, wrangling, and enhancement</h2>
<p>The ride-sharing vehicles in New York City are regulated by the Taxi &amp; Limousine Commission (TLC), and the trip record data since 2009 can be downloaded from the <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">TLC Data Portal</a>. The dataset contains basic information about each ride, including: pickup and drop off time and location, whether trips are pooled, and information about fares and tips. To protect privacy, the trips data are anonymized, so pickup and drop off locations are generalized to the nearest taxi zones, no customer data is available, and drivers can not be linked to particular rides they provided.</p>
<p>The trip record of each month was downloaded as a PARQUET file from the <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">TLC Data Portal</a>.The data preprocessing steps performed include:</p>
<ul>
<li>Removing rides with zero distance or zero fare;</li>
<li>Creating datetime fields with the ride start and end datetimes rounded to the nearest hour; and</li>
<li>Aggregating the dataset by hour and taxi zone and calculating trip counts, average fare, average distance, and average duration</li>
</ul>
<p>Since the dataset is very large (around 15 million trip records for each month), in addition to the wrangling steps above, I have also sampled 10% of individual trip records for Exploratory Data Analysis (EDA).</p>
<p>In order to enrich the rideshare dataset, I merged in additional data sources that many enhance understanding and prediction of trip demands. A weather dataset from <a href="https://forecast.weather.gov/data/obhistory/KLGA.html">NOAA LaGuardia Airport station</a> containing hourly and daily aggregated measurements of temperature, wind, and precipitation was merged with the Trips data by matching on the ride pickup datetime field. Taxi Zone boundary geojason file was also downloaded from the <a href="https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc">NYC OpenData</a>  and loaded into geodataframes using the geopandas python library.</p>
<p>           
           </p>
<h2 id="3-eda-and-statistical-analysis">3. EDA and statistical analysis</h2>
<p>In this section, we will conduct Exploratory Data Analysis (EDA) and Statistical Analysis to identify interesting temporal patterns, spatial patterns, spatiotemporal patterns. We will also investigate effects of weather (e.g., temperature and precipitation) on rideshare usage as well as rider&rsquo;s tipping behavior. An excellent example of Exploratory Data Analysis (EDA) can be found <a href="https://github.com/LisaATaylor/Rideshare">here</a>.</p>
<h3 id="31-eda-findings-temporal-pattern">3.1. EDA findings: Temporal pattern</h3>
<p>In the figure below, we plotted the systemwide hourly rideshare usage as a function of time over the entire data period. From this figure, we find that rideshare usage is cyclical, with a usage pattern demonstrating both hourly and weekly components.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-2b.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-2b.png" alt=""> </a></p>
<p>The cyclical pattern is further shown below by plotting the hourly demand vs. day and time. From this figure, we notice that during weekdays, there are two peaks, one for morning rush hour and the other for evening rush hour. During weekends, there is only one demand peak in the late evening.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-3.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-3.png" alt=""> </a></p>
<p>           </p>
<h3 id="32-eda-findings-spatial-pattern">3.2. EDA findings: Spatial pattern</h3>
<p>The highest rideshare usage occurs in Crown Heights, where several subway stations connecting Brooklyn with Manhattan. Downtown core (e.g., East Village) and airports (e.g., JFK and LGA) also have very high rideshare usage. Away from these areas, the rideshare usage drops of quickly. The following choropleth map, which displays the sum of total pickups and drop offs by taxi zone, illustrates this pattern clearly.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-4.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-4.png" alt=""> </a></p>
<p>           </p>
<h3 id="33-eda-findings-spatiotemporal-patterns">3.3. EDA findings: Spatiotemporal patterns</h3>
<p>Rideshare usage patterns vary across the city. The data demonstrates distinct patterns for airports, downtown, residential neighborhoods, etc. The following heatmap shows usage patterns for a few areas within the city, and show distinct variations between airports, downtown, neighborhood and park.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-5.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-5.png" alt=""> </a></p>
<p>           </p>
<h3 id="34-eda-findings-weather-effects">3.4. EDA findings: Weather effects</h3>
<p>The relationship between rideshare usage patterns and weather is not obvious. When viewed at the daily level, rideshare utilization patterns do not appear sensitive to either temperature or precipitation.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-6.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-6.png" alt=""> </a></p>
<p>When we zoom to the hourly level, there appears to be no statistical relationship between rideshare usage and precipitation, and the rideshare usage only decreases lightly.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-7.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-7.png" alt=""> </a></p>
<p>If we isolate a more specific time window (e.g., PM commute and Mid evening), we can isolate small effects such as shown below, with utilization increasing during PM commute period and mid evening.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-8.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-8.png" alt=""> </a></p>
<p>           </p>
<h3 id="35-eda-findings-tipping">3.5. EDA findings: Tipping</h3>
<p>From the figure below, we can find that riders tip the driver on approximately 15% of rides, and that for those who tip the driver, the tips are typically 20&ndash;50% of the fare.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-9.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-9.png" alt=""> </a></p>
<p>Factors influencing the likelihood of a tip include whether the ride originates or ends at the airport. A two-sample z-test of the proportion of tipped rides between airport/non-airport rides demonstrated a statistically significant increase in the odds of tipping for airport pickups.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Two sample Z-test for difference between sample proportions</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># CLT applies if np and n(1-p) are both &gt;5</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># H0:  p_air = p_other</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Alpha = 0.05 --&gt; Z = +/- 1.96</span>
</span></span><span style="display:flex;"><span>p_all <span style="color:#f92672">=</span> tipsdf[<span style="color:#e6db74">&#39;NumTippedRides&#39;</span>]<span style="color:#f92672">.</span>sum()<span style="color:#f92672">/</span>tipsdf[<span style="color:#e6db74">&#39;NumRides&#39;</span>]<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>p_all
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n_other<span style="color:#f92672">=</span>tipsdf<span style="color:#f92672">.</span>loc[<span style="color:#66d9ef">False</span>,<span style="color:#e6db74">&#39;NumRides&#39;</span>]
</span></span><span style="display:flex;"><span>n_air<span style="color:#f92672">=</span>tipsdf<span style="color:#f92672">.</span>loc[<span style="color:#66d9ef">True</span>,<span style="color:#e6db74">&#39;NumRides&#39;</span>]
</span></span><span style="display:flex;"><span>p_other<span style="color:#f92672">=</span>tipsdf<span style="color:#f92672">.</span>loc[<span style="color:#66d9ef">False</span>,<span style="color:#e6db74">&#39;PropTips&#39;</span>]
</span></span><span style="display:flex;"><span>p_air<span style="color:#f92672">=</span>tipsdf<span style="color:#f92672">.</span>loc[<span style="color:#66d9ef">True</span>,<span style="color:#e6db74">&#39;PropTips&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sem <span style="color:#f92672">=</span>p_all<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>p_all)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>n_other <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>n_air) <span style="color:#75715e">#n is big, this value becomes very small</span>
</span></span><span style="display:flex;"><span>Z <span style="color:#f92672">=</span> (p_air<span style="color:#f92672">-</span>p_other)<span style="color:#f92672">/</span>np<span style="color:#f92672">.</span>sqrt(sem) <span style="color:#75715e">#SEM is small, so Z gets very large</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Z-score: </span><span style="color:#e6db74">{:0.0f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(Z))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Z-score: 256</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#This is a high z-score</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Reject H0, conclude the odds of getting a tip are higher for airport pickups</span>
</span></span></code></pre></div><p>The following box plot, which shows the percentage of tipped rides (AirportDOorPU=True indicates the trip&rsquo;s Pickup location or Drop off location is an airport), illustrates this effect.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-10.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-10.png" alt=""> </a></p>
<p>           
           </p>
<h2 id="4-clustering-analysis">4. Clustering analysis</h2>
<p>In this section, a clustering model was developed to gain a better understanding of how ridesharing is being used in New York City. For this analysis, the rides data were grouped on the following fields:</p>
<ul>
<li>Taxi zone of Pickup;</li>
<li>Taxi zone of Drop off;</li>
<li>Period within the day: early morning (11 p.m.&ndash;5 a.m.), morning (5 a.m.&ndash;9 a.m.), midday (9 a.m.&ndash;1 p.m.), afternoon (1 p.m.&ndash;4 p.m.), evening (4 p.m.&ndash;7 p.m.), and late evening (7 p.m.&ndash;11 p.m.);</li>
<li>whether the ride occurred on a weekend or weekday;</li>
<li>whether the ride involved the airport as Pickup or Drop off.</li>
</ul>
<p>The timing of each trip was also simplified into larger buckets (weekend/weekday, period of day) to improve interpretability of outcomes. A boolean airport flag was added since this attribute was found during EDA to have a strong influence on rideshare utilization. Holidays were excluded from the analysis. Within each grouping, the following aggregated values were calculated: number of rides, average ride duration, average ride distance, and average fare.</p>
<p>To prepare the data for fitting a clustering model, the grouped dataset was pivoted to create columns containing ride counts for each grouping of weekend/weekday and day period. After this reworking, the final dataset contained a single record for each route, each with a MultiIndex containing the unique combinations of drop off and pickup Community Areas, and columns containing the ride count columns, the airport flag, and the average fare for the route.</p>
<p>The KMeans clustering algorithm was selected for this analysis. This model requires the user to specify the number of clusters k before fitting the model. To determine an appropriate value of k, the inertia (within-cluster sum of squares) was calculated for values of k between 2 and 19.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-11a.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-11a.png" alt=""> </a></p>
<p>The silhouette score and associated plots were generated for a variety of values of k. The results shown below suggested a plateau in the
silhouette score above k=7. This is also in consistency with thea small elbow near k=7 shown in the second figure below.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-11.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-11.png" alt=""> </a></p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-12.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-12.png" alt=""> </a></p>
<p>In this study, the KMeans model  was fit to the dataset using a variety of k values. The data was scaled prior to input to the algorithm. The result at k=7 showed interesting patterns and will be used for the interpretation of results shown below.</p>
<p>A dashboard was built using IPywidgets to facilitate the evaluation of results. The dashboard has a single widget, for selection of the cluster, and outputs visualizations of the routes, distribution of fares, and temporal utilization patterns associated with each cluster. As an example, clustering results of clusters 2, 4 and 5, are shown below:</p>
<p>The figure below is for cluster 2, which shows strong commuting patterns in Crown Heights where riders take subway to or from Manhattan. Another strong pattern near the downtown area (East Village) is also shown in this figure. These routes all represent groups of rides with relatively low fares.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-13b.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-13b.png" alt=""> </a></p>
<p>The figure below is for cluster 4, which shows short distance ride with pickup location and drop off location in the same taxi zone. These rides mainly occurs during midday and afternoon, and the average fare is close to the Minimum Fare.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-14b.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-14b.png" alt=""> </a></p>
<p>Cluster 5 was identified with airport pickups and is shown in the figure below. This cluster demonstrates a weekday early morning peak, and a wide distribution of fares.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-15.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-15.png" alt=""> </a></p>
<p>           
           </p>
<h2 id="5-rideshare-usage-prediction">5. Rideshare usage prediction</h2>
<p>In this section, we will develop four models to predict the rideshare usage. In particular, the systemwide hourly rideshare usage will be predicted by two univariate time series models: Seasonal Autoregressive Integrated Moving Average (SARIMA), and Gaussian Process (GP).</p>
<p>           </p>
<h3 id="51-seasonal-autoregressive-integrated-moving-average-sarima">5.1. Seasonal Autoregressive Integrated Moving Average (SARIMA)</h3>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-17.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-17.png" alt=""> </a></p>
<p>In the figure above, systemwide hourly rideshare demands of 20 weeks starting from March 12 is shown. We choose this time window for Seasonal Autoregressive Integrated Moving Average (SARIMA) model because it better satisfies the stationarity requirement. From the figures above, we can find that: (1) the data has seasonality of 168 hours (i.e., a week); (2) there is no obvious trend in data (will test later using Augmented Dickey–Fuller test); and (3) There is no obvious change in the variance of data, so we do not need to take log transform of data. In the code box below, we will conduct seasonal differencing of data and then take Augmented Dickey–Fuller test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df_D_168 <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>diff(periods<span style="color:#f92672">=</span><span style="color:#ae81ff">168</span>)<span style="color:#f92672">.</span>dropna()
</span></span><span style="display:flex;"><span>df_D_168_adf <span style="color:#f92672">=</span> adfuller(df_D_168)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;1. ADF : &#34;</span>,df_D_168_adf[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;2. P-Value : &#34;</span>, df_D_168_adf[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;3. Num Of Lags : &#34;</span>, df_D_168_adf[<span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;4. Num Of Observations Used For ADF Regression and Critical Values Calculation :&#34;</span>, df_D_168_adf[<span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;5. Critical Values :&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> key, val <span style="color:#f92672">in</span> df_D_168_adf[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#34;</span>,key, <span style="color:#e6db74">&#34;: &#34;</span>, val)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output:</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1.</span> ADF :  <span style="color:#f92672">-</span><span style="color:#ae81ff">10.148423918150554</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2.</span> P<span style="color:#f92672">-</span>Value :  <span style="color:#ae81ff">8.070162297528182e-18</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3.</span> Num Of Lags :  <span style="color:#ae81ff">28</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4.</span> Num Of Observations Used For ADF Regression <span style="color:#f92672">and</span> Critical Values Calculation : <span style="color:#ae81ff">6355</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5.</span> Critical Values :
</span></span><span style="display:flex;"><span>	 <span style="color:#ae81ff">1</span><span style="color:#f92672">%</span> :  <span style="color:#f92672">-</span><span style="color:#ae81ff">3.431379416735103</span>
</span></span><span style="display:flex;"><span>	 <span style="color:#ae81ff">5</span><span style="color:#f92672">%</span> :  <span style="color:#f92672">-</span><span style="color:#ae81ff">2.8619949122326487</span>
</span></span><span style="display:flex;"><span>	 <span style="color:#ae81ff">10</span><span style="color:#f92672">%</span> :  <span style="color:#f92672">-</span><span style="color:#ae81ff">2.5670121466584046</span>
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-18.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-18.png" alt=""> </a></p>
<p>From the figure above and the Augmented Dickey–Fuller (adfuller) test above, we can find that the data has stationarity and trend-stationarity (p-value is very small, 8.07e-18, so we will reject the null hypothesis and accept the alternative hypothesis). So for Seasonal ARIMA model SARIMA(P, D, Q, p, d, q)_s, we will set D = 1, d = 0, and s = 168.</p>
<p>As Parsimony principle suggests, we will keep P + D + Q + p + d + q &lt;= 6. Since D = 1 and d = 0, we can have P + Q + p + q &lt;=5.</p>
<p>From the Autocorrelation plot, we can find there are quite a few closer spikes, so the potential values of Moving Average (MA) order q could be q = 0/1/2/3/4/5.</p>
<p>Also from the Autocorrelation plot, we can find spikes around seasonal lags of 168 hours, so the potential values of the Seasonal Moving Average (SMA) order Q could be Q = 0/1.</p>
<p>Similarly from the Partial Autocorrelation plot, we can find there are 2 closer spikes, so the potential values of Autoregressive (AR) order p could be p = 0/1/2.</p>
<p>Also from the Partial Autocorrelation plot, we can find spikes around seasonal lags of 168 hours, so the potential values of the Seasonal Autoregressive (SAR) order P could be P = 0/1.</p>
<p>In summary by analyzing the plots above, we have the following potential orders as shown below. Also we need to satisfy P + Q + p + q &lt;=5 to follow the Parsimony principle: (1) P = 0/1, (2) Q = 0/1, (3) p = 0/1/2, (4) q = 0/1/2/3/4/5.</p>
<p>During the development of SARIMA model, we have fit few different models and compare their Akaike Information Criteria (AIC).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">===================================================================</span>
</span></span><span style="display:flex;"><span>P	D	Q	s	p	d	q	AIC	        Ljung<span style="color:#f92672">-</span>Box (L1) (Q)	Prob(Q)
</span></span><span style="display:flex;"><span><span style="color:#f92672">===================================================================</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">26695.77</span>	<span style="color:#ae81ff">838.9</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25965.16</span>	<span style="color:#ae81ff">108.9</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25721.78</span>	<span style="color:#ae81ff">18.9</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25638.62</span>	<span style="color:#ae81ff">4.7</span>	                <span style="color:#ae81ff">0.03</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">4</span>	<span style="color:#ae81ff">25603.19</span>	<span style="color:#ae81ff">1.9</span>	                <span style="color:#ae81ff">0.17</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">5</span>	<span style="color:#ae81ff">25587.32</span>	<span style="color:#ae81ff">1.3</span>	                <span style="color:#ae81ff">0.26</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25579.33</span>	<span style="color:#ae81ff">1.1</span>	                <span style="color:#ae81ff">0.30</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25582.59</span>	<span style="color:#ae81ff">0.3</span>	                <span style="color:#ae81ff">0.59</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25581.56</span>	<span style="color:#ae81ff">0.4</span>	                <span style="color:#ae81ff">0.54</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25581.98</span>	<span style="color:#ae81ff">0.4</span>	                <span style="color:#ae81ff">0.53</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">4</span>	<span style="color:#ae81ff">25580.28</span>	<span style="color:#ae81ff">0.4</span>	                <span style="color:#ae81ff">0.52</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25582.62</span>	<span style="color:#ae81ff">0.2</span>	                <span style="color:#ae81ff">0.63</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25573.31</span>	<span style="color:#ae81ff">0.2</span>	                <span style="color:#ae81ff">0.69</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25570.94</span>	<span style="color:#ae81ff">0.6</span>	                <span style="color:#ae81ff">0.45</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25585.27</span>	<span style="color:#ae81ff">0.4</span>	                <span style="color:#ae81ff">0.55</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">26707.22</span>	<span style="color:#ae81ff">848.0</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25994.98</span>	<span style="color:#ae81ff">116.6</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25736.47</span>	<span style="color:#ae81ff">23.1</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25604.12</span>	<span style="color:#ae81ff">6.6</span>	                <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">4</span>	<span style="color:#ae81ff">25567.29</span>	<span style="color:#ae81ff">3.1</span>	                <span style="color:#ae81ff">0.08</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25505.32</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.84</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25507.31</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.77</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25508.33</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.72</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25509.29</span>	<span style="color:#ae81ff">0.2</span>	                <span style="color:#ae81ff">0.69</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25507.30</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.76</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25509.31</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.78</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25542.66</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.74</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">26754.48</span>	<span style="color:#ae81ff">847.6</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25953.17</span>	<span style="color:#ae81ff">116.4</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25699.62</span>	<span style="color:#ae81ff">22.4</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25608.02</span>	<span style="color:#ae81ff">6.4</span>	                <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">4</span>	<span style="color:#ae81ff">25571.81</span>	<span style="color:#ae81ff">3.0</span>	                <span style="color:#ae81ff">0.08</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25517.75</span>	<span style="color:#ae81ff">0.3</span>	                <span style="color:#ae81ff">0.57</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25519.73</span>	<span style="color:#ae81ff">0.2</span>	                <span style="color:#ae81ff">0.64</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25520.22</span>	<span style="color:#ae81ff">0.3</span>	                <span style="color:#ae81ff">0.59</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25520.97</span>	<span style="color:#ae81ff">0.3</span>	                <span style="color:#ae81ff">0.57</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25519.73</span>	<span style="color:#ae81ff">0.2</span>	                <span style="color:#ae81ff">0.64</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25518.62</span>	<span style="color:#ae81ff">0.1</span>	                <span style="color:#ae81ff">0.75</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25522.84</span>	<span style="color:#ae81ff">0.3</span>	                <span style="color:#ae81ff">0.61</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">26715.96</span>	<span style="color:#ae81ff">846.3</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25936.52</span>	<span style="color:#ae81ff">114.5</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25683.84</span>	<span style="color:#ae81ff">21.4</span>	            <span style="color:#ae81ff">0.00</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">25592.39</span>	<span style="color:#ae81ff">5.7</span>	                <span style="color:#ae81ff">0.02</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25496.02</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.99</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25498.01</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.93</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">25499.19</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.87</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">25497.98</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.92</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">168</span>	<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">25500.02</span>	<span style="color:#ae81ff">0.0</span>	                <span style="color:#ae81ff">0.94</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">===================================================================</span>
</span></span></code></pre></div><p>As shown above, we find that the model SARIMA(P=1, D=1, Q=1, s=168, p=1, d=0, q=0) has the lowest AIC value and will be selected as our model.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-19.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-19.png" alt=""> </a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>seasonal_order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">168</span>)
</span></span><span style="display:flex;"><span>order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;(P, D, Q, s) = &#39;</span>, seasonal_order, <span style="color:#e6db74">&#39;, (p, d, q) = &#39;</span>, order)
</span></span><span style="display:flex;"><span>start_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">=</span>sm<span style="color:#f92672">.</span>tsa<span style="color:#f92672">.</span>SARIMAX(endog<span style="color:#f92672">=</span>df[<span style="color:#ae81ff">1680</span>:<span style="color:#ae81ff">3360</span>], order<span style="color:#f92672">=</span>order, seasonal_order<span style="color:#f92672">=</span>seasonal_order)
</span></span><span style="display:flex;"><span>model_fit <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(disp<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>elapsed_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start_time
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;elapsed time: &#39;</span>, elapsed_time)
</span></span><span style="display:flex;"><span>print(model_fit<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><p>The figure below shows the prediction from the SARIMA(P=1, D=1, Q=1, s=168, p=1, d=0, q=0) that we developed above. From this figure, we can see that SARIMA model gives pretty accurate prediction, and it can successfully capture the hourly and weekly components. Also, since the Ljung-Box test has Q = 0.00 and Prob(Q) = 0.99, we can accept the null hypothesis of the test and conclude that the residuals are independent.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-20.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-20.png" alt=""> </a></p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-21.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-21.png" alt=""> </a></p>
<p>           </p>
<h3 id="52-gaussian-process-gp">5.2. Gaussian Process (GP)</h3>
<p>From the figure of systemwide rideshare demand shown in Section 3.1., we can observe that there is a lower trip count near the beginning of February 2021, and that there is a higher trip count near the end of October. To ensure data consistency and (weak) stationary, we will focus on data between Mar 1 and Sep 30 in this study.</p>
<p>Since the length of the dataset is 5136, We will use 80% (5136 * 0.8 = 4109) as training set, and 20% (5136 - 4109 = 1027) for test. The figure below shows the training and test data after subtracting the mean from the training data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_mean <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;trip_count&#39;</span>]<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>print(y_mean)
</span></span><span style="display:flex;"><span>df_train[<span style="color:#e6db74">&#39;trip_count&#39;</span>] <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;trip_count&#39;</span>] <span style="color:#f92672">-</span> y_mean
</span></span><span style="display:flex;"><span>df_test[<span style="color:#e6db74">&#39;trip_count&#39;</span>] <span style="color:#f92672">=</span> df_test[<span style="color:#e6db74">&#39;trip_count&#39;</span>] <span style="color:#f92672">-</span> y_mean
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-22.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-22.png" alt=""> </a></p>
<p>Designing proper kernel is crucial for Gaussian Process. To design the kernel to use with our Gaussian process, we can make some assumption regarding the data at hand. We observe that they have several characteristics, and we can use different appropriate kernel that would capture these features.</p>
<ul>
<li>a pronounced daily variation,</li>
<li>a pronounced weekly variation,</li>
<li>some smaller irregularities and white noise</li>
</ul>
<p>The daily variation is explained by the periodic exponential sine squared kernel with a fixed periodicity of 24 hour or 1 day. The length-scale of this periodic component, controlling its smoothness, is a free parameter. In order to allow decaying away from exact periodicity, the product with an RBF kernel is taken. The length-scale of this RBF component controls the decay time and is a further free parameter. This type of kernel is also known as locally periodic kernel.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># periodic range : 0.5 --2 days</span>
</span></span><span style="display:flex;"><span>k1 <span style="color:#f92672">=</span> ConstantKernel(constant_value<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> ExpSineSquared(length_scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, periodicity<span style="color:#f92672">=</span><span style="color:#ae81ff">24.0</span>, periodicity_bounds<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">50</span>))
</span></span></code></pre></div><p>Similarly, the weekly variation is explained by the periodic exponential sine squared kernel with a fixed periodicity of 168 hour or 7 days. The length-scale of this periodic component, controlling its smoothness, is a free parameter. In order to allow decaying away from exact periodicity, the product with an RBF kernel is taken. The length-scale of this RBF component controls the decay time and is a further free parameter. This type of kernel is also known as locally periodic kernel.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># periodic range : 1 --2 weeks</span>
</span></span><span style="display:flex;"><span>k2 <span style="color:#f92672">=</span> ConstantKernel(constant_value<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> ExpSineSquared(length_scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, periodicity<span style="color:#f92672">=</span><span style="color:#ae81ff">168.0</span>, periodicity_bounds<span style="color:#f92672">=</span>(<span style="color:#ae81ff">150</span>, <span style="color:#ae81ff">350</span>))
</span></span></code></pre></div><p>Finally, the noise in the dataset can be accounted with a kernel consisting of an RBF kernel contribution, which shall explain the correlated noise components such as local weather phenomena, and a white kernel contribution for the white noise. The relative amplitudes and the RBF’s length scale are further free parameters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># k4 = ConstantKernel(constant_value=0.1) * RBF(length_scale=0.1) + WhiteKernel(noise_level=0.1**2, noise_level_bounds=(1e-5, 1))</span>
</span></span><span style="display:flex;"><span>k4 <span style="color:#f92672">=</span> WhiteKernel(noise_level<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><p>Thus, our final kernel is an addition of all previous kernel, and we are ready to use a Gaussian process regressor and fit the available data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>kernel_1  <span style="color:#f92672">=</span> k1 <span style="color:#f92672">+</span> k2 <span style="color:#f92672">+</span> k4
</span></span><span style="display:flex;"><span>gp1 <span style="color:#f92672">=</span> GaussianProcessRegressor(kernel<span style="color:#f92672">=</span>kernel_1, n_restarts_optimizer<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, normalize_y<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>gp1<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>gp1<span style="color:#f92672">.</span>kernel_
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1.25</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> ExpSineSquared(length_scale<span style="color:#f92672">=</span><span style="color:#ae81ff">0.662</span>, periodicity<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span>) <span style="color:#f92672">+</span> 
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1.35</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> ExpSineSquared(length_scale<span style="color:#f92672">=</span><span style="color:#ae81ff">0.113</span>, periodicity<span style="color:#f92672">=</span><span style="color:#ae81ff">168</span>) <span style="color:#f92672">+</span> 
</span></span><span style="display:flex;"><span>WhiteKernel(noise_level<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0354</span>)
</span></span></code></pre></div><p>To generate predictions and evaluate the model, first we will scale back the data to our original scale. Then, to check the performance, we will plot the original and predicted time series plot, as shown below. From this figure, we can see that for both the training set and test set, the Gaussian Process model developed in this work can provide accurate prediction, capturing both the daily and weekly patterns.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_pred, y_std <span style="color:#f92672">=</span> gp1<span style="color:#f92672">.</span>predict(X, return_std<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>data_df[<span style="color:#e6db74">&#39;y_pred&#39;</span>] <span style="color:#f92672">=</span> y_pred <span style="color:#f92672">+</span> y_mean
</span></span><span style="display:flex;"><span>data_df[<span style="color:#e6db74">&#39;y_std&#39;</span>] <span style="color:#f92672">=</span> y_std
</span></span><span style="display:flex;"><span>data_df[<span style="color:#e6db74">&#39;y_pred_lwr&#39;</span>] <span style="color:#f92672">=</span> data_df[<span style="color:#e6db74">&#39;y_pred&#39;</span>] <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>data_df[<span style="color:#e6db74">&#39;y_std&#39;</span>]
</span></span><span style="display:flex;"><span>data_df[<span style="color:#e6db74">&#39;y_pred_upr&#39;</span>] <span style="color:#f92672">=</span> data_df[<span style="color:#e6db74">&#39;y_pred&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>data_df[<span style="color:#e6db74">&#39;y_std&#39;</span>]
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-23.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-23.png" alt=""> </a></p>
<p>Finally, we computed the Covariance Matrices and the results are shown below. A great reference is <a href="https://juanitorduz.github.io/gaussian_process_reg/">here</a>. We employ the following notation: K = K(X, X), K_star = K(X*, X), and K_star2 = K(X*, X*). From the figure below, we observe that (1) Covariance Matrices is symmetric; (2) strong effects of 24 hours (i.e., daily cyclic trend) and 168 hours (i.e., weekly cyclic trend) are observed. These observations are as expected and in very good agreement with the data.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-24.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-24.png" alt=""> </a></p>
<p>           </p>
<h3 id="53-vector-autoregression-var">5.3. Vector Autoregression (VAR)</h3>
<p>There are 263 taxi zones in New York city, the 61 taxi zones with highest rideshare usage only take 23% of taxi zones and contribute more than 50% of rideshare usage. These 61 taxi zones with highest rideshare usage will be predicted by the two multivariate time series models studied in this work, including Vector Autoregression (VAR) in this section and Recurrent Neural Network (RNN) in the next section.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-16.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-16.png" alt=""> </a></p>
<p>Similar to the SARIMA model in Section 5.1., hourly rideshare demands of 20 weeks starting from March 12 will be used. We choose this time window for Vector Autoregression (VAR) model because it better satisfies the stationarity requirement. One key difference is that in Section 5.1., the SARIMA model is an univariate time series model which will predict the systemwide total rideshare demand; while the VAR model developed in this section is a multivariate time series model which will predict the rideshare demand of 61 taxi zones simultaneously.</p>
<p>The first step of developing VAR model is to check Granger Causality of all possible combinations of the Time series <a href="https://www.machinelearningplus.com/time-series/vector-autoregression-examples-python/">Ref</a>. The values in the figure below are the P-Values. P-Values lesser than the significance level (0.05), implies the Null Hypothesis that the coefficients of the corresponding past values is zero, that is, the X does not cause Y can be rejected. Looking at the P-Values in the figure below, we can pretty much observe that all the variables (time series) in the system are interchangeably causing each other. This makes this system of multi time series a good candidate for using VAR models to forecast.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>maxlag<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>
</span></span><span style="display:flex;"><span>test <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;ssr_chi2test&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">grangers_causation_matrix</span>(data, variables, test<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ssr_chi2test&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(np<span style="color:#f92672">.</span>zeros((len(variables), len(variables))), columns<span style="color:#f92672">=</span>variables, index<span style="color:#f92672">=</span>variables)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> df<span style="color:#f92672">.</span>columns:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> df<span style="color:#f92672">.</span>index:
</span></span><span style="display:flex;"><span>            test_result <span style="color:#f92672">=</span> grangercausalitytests(data[[r, c]], maxlag<span style="color:#f92672">=</span>maxlag, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>            p_values <span style="color:#f92672">=</span> [round(test_result[i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>][<span style="color:#ae81ff">0</span>][test][<span style="color:#ae81ff">1</span>],<span style="color:#ae81ff">4</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(maxlag)]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> verbose: print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Y = </span><span style="color:#e6db74">{</span>r<span style="color:#e6db74">}</span><span style="color:#e6db74">, X = </span><span style="color:#e6db74">{</span>c<span style="color:#e6db74">}</span><span style="color:#e6db74">, P Values = </span><span style="color:#e6db74">{</span>p_values<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            min_p_value <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>min(p_values)
</span></span><span style="display:flex;"><span>            df<span style="color:#f92672">.</span>loc[r, c] <span style="color:#f92672">=</span> min_p_value
</span></span><span style="display:flex;"><span>    df<span style="color:#f92672">.</span>columns <span style="color:#f92672">=</span> [var <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_x&#39;</span> <span style="color:#66d9ef">for</span> var <span style="color:#f92672">in</span> variables]
</span></span><span style="display:flex;"><span>    df<span style="color:#f92672">.</span>index <span style="color:#f92672">=</span> [var <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_y&#39;</span> <span style="color:#66d9ef">for</span> var <span style="color:#f92672">in</span> variables]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> df
</span></span><span style="display:flex;"><span>grangers <span style="color:#f92672">=</span> grangers_causation_matrix(df_train, variables <span style="color:#f92672">=</span> df_train<span style="color:#f92672">.</span>columns)
</span></span><span style="display:flex;"><span>fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">24</span>,<span style="color:#ae81ff">16</span>))
</span></span><span style="display:flex;"><span>dataplot <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>heatmap(grangers, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;icefire&#34;</span>, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, ax<span style="color:#f92672">=</span>ax)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-25.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-25.png" alt=""> </a></p>
<p>Next we need to check for Stationarity and make the time series stationary if necessary <a href="https://www.machinelearningplus.com/time-series/vector-autoregression-examples-python/">Ref</a>. As shown in the command box below, we conducted Augmented Dickey–Fuller test for each column, and for simplicity, only the output of first column is shown (full results are available in the script P3-5-VAR.ipynb). The Augmented Dickey-Fuller Test results confirmed that each column is Stationary and as a consequence the dataset is suitable for VAR model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">adfuller_test</span>(series, signif<span style="color:#f92672">=</span><span style="color:#ae81ff">0.05</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Perform ADFuller to test for Stationarity of given series and print report&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    r <span style="color:#f92672">=</span> adfuller(series, autolag<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;AIC&#39;</span>)
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;test_statistic&#39;</span>:round(r[<span style="color:#ae81ff">0</span>], <span style="color:#ae81ff">4</span>), <span style="color:#e6db74">&#39;pvalue&#39;</span>:round(r[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">4</span>), <span style="color:#e6db74">&#39;n_lags&#39;</span>:round(r[<span style="color:#ae81ff">2</span>], <span style="color:#ae81ff">4</span>), <span style="color:#e6db74">&#39;n_obs&#39;</span>:r[<span style="color:#ae81ff">3</span>]}
</span></span><span style="display:flex;"><span>    p_value <span style="color:#f92672">=</span> output[<span style="color:#e6db74">&#39;pvalue&#39;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">adjust</span>(val, length<span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>): <span style="color:#66d9ef">return</span> str(val)<span style="color:#f92672">.</span>ljust(length)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;    Augmented Dickey-Fuller Test on &#34;</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;&#39;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">   &#34;</span>, <span style="color:#e6db74">&#39;-&#39;</span><span style="color:#f92672">*</span><span style="color:#ae81ff">47</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; Null Hypothesis: Data has unit root. Non-Stationary.&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; Significance Level    = </span><span style="color:#e6db74">{</span>signif<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; Test Statistic        = </span><span style="color:#e6db74">{</span>output[<span style="color:#e6db74">&#34;test_statistic&#34;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; No. Lags Chosen       = </span><span style="color:#e6db74">{</span>output[<span style="color:#e6db74">&#34;n_lags&#34;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; No. Observations       = </span><span style="color:#e6db74">{</span>output[<span style="color:#e6db74">&#34;n_obs&#34;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> key,val <span style="color:#f92672">in</span> r[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; Critical value </span><span style="color:#e6db74">{</span>adjust(key)<span style="color:#e6db74">}</span><span style="color:#e6db74"> = </span><span style="color:#e6db74">{</span>round(val, <span style="color:#ae81ff">3</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> p_value <span style="color:#f92672">&lt;=</span> signif:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34; =&gt; P-Value = </span><span style="color:#e6db74">{</span>p_value<span style="color:#e6db74">}</span><span style="color:#e6db74">. Rejecting Null Hypothesis.&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34; =&gt; Series is Stationary.&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34; =&gt; P-Value = </span><span style="color:#e6db74">{</span>p_value<span style="color:#e6db74">}</span><span style="color:#e6db74">. Weak evidence to reject the Null Hypothesis.&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34; =&gt; Series is Non-Stationary.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ADF Test on each column</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> name, column <span style="color:#f92672">in</span> df_train<span style="color:#f92672">.</span>iteritems():
</span></span><span style="display:flex;"><span>    adfuller_test(column, name<span style="color:#f92672">=</span>column<span style="color:#f92672">.</span>name)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output</span>
</span></span><span style="display:flex;"><span>    Augmented Dickey<span style="color:#f92672">-</span>Fuller Test on <span style="color:#e6db74">&#34;61&#34;</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">-----------------------------------------------</span>
</span></span><span style="display:flex;"><span> Null Hypothesis: Data has unit root<span style="color:#f92672">.</span> Non<span style="color:#f92672">-</span>Stationary<span style="color:#f92672">.</span>
</span></span><span style="display:flex;"><span> Significance Level    <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.05</span>
</span></span><span style="display:flex;"><span> Test Statistic        <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">5.0669</span>
</span></span><span style="display:flex;"><span> No<span style="color:#f92672">.</span> Lags Chosen       <span style="color:#f92672">=</span> <span style="color:#ae81ff">25</span>
</span></span><span style="display:flex;"><span> No<span style="color:#f92672">.</span> Observations       <span style="color:#f92672">=</span> <span style="color:#ae81ff">1654</span>
</span></span><span style="display:flex;"><span> Critical value <span style="color:#ae81ff">1</span><span style="color:#f92672">%</span>     <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">3.434</span>
</span></span><span style="display:flex;"><span> Critical value <span style="color:#ae81ff">5</span><span style="color:#f92672">%</span>     <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2.863</span>
</span></span><span style="display:flex;"><span> Critical value <span style="color:#ae81ff">10</span><span style="color:#f92672">%</span>    <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2.568</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=&gt;</span> P<span style="color:#f92672">-</span>Value <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span><span style="color:#f92672">.</span> Rejecting Null Hypothesis<span style="color:#f92672">.</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=&gt;</span> Series <span style="color:#f92672">is</span> Stationary<span style="color:#f92672">.</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">...</span>
</span></span></code></pre></div><p>Next we will select the Order (P) of Vector Autoregression (VAR) model in the command box below. The program will provide Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), Final prediction error (FPE), and Hannan–Quinn information criterion (HQIC). The criterion we used is Akaike Information Criterion (AIC). Based on AIC, we will set p = 3.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model <span style="color:#f92672">=</span> VAR(df_train)
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>select_order(maxlags<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>x<span style="color:#f92672">.</span>summary()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output</span>
</span></span><span style="display:flex;"><span>VAR Order Selection (<span style="color:#f92672">*</span> highlights the minimums)
</span></span><span style="display:flex;"><span>    AIC     BIC     FPE          HQIC
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span>   <span style="color:#ae81ff">363.5</span>   <span style="color:#ae81ff">363.7</span>   <span style="color:#ae81ff">7.004e+157</span>   <span style="color:#ae81ff">363.5</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>   <span style="color:#ae81ff">343.5</span>   <span style="color:#ae81ff">355.8</span><span style="color:#f92672">*</span>  <span style="color:#ae81ff">1.500e+149</span>   <span style="color:#ae81ff">348.0</span><span style="color:#f92672">*</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span>   <span style="color:#ae81ff">342.0</span>   <span style="color:#ae81ff">366.3</span>   <span style="color:#ae81ff">3.328e+148</span>   <span style="color:#ae81ff">351.0</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3</span>   <span style="color:#ae81ff">341.7</span><span style="color:#f92672">*</span>  <span style="color:#ae81ff">378.2</span>   <span style="color:#ae81ff">2.710e+148</span><span style="color:#f92672">*</span>  <span style="color:#ae81ff">355.2</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span>   <span style="color:#ae81ff">342.2</span>   <span style="color:#ae81ff">390.7</span>   <span style="color:#ae81ff">4.657e+148</span>   <span style="color:#ae81ff">360.2</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5</span>   <span style="color:#ae81ff">342.9</span>   <span style="color:#ae81ff">403.5</span>   <span style="color:#ae81ff">1.069e+149</span>   <span style="color:#ae81ff">365.3</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">6</span>   <span style="color:#ae81ff">343.7</span>   <span style="color:#ae81ff">416.3</span>   <span style="color:#ae81ff">2.771e+149</span>   <span style="color:#ae81ff">370.6</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">7</span>   <span style="color:#ae81ff">344.5</span>   <span style="color:#ae81ff">429.3</span>   <span style="color:#ae81ff">8.655e+149</span>   <span style="color:#ae81ff">375.9</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8</span>   <span style="color:#ae81ff">345.3</span>   <span style="color:#ae81ff">442.1</span>   <span style="color:#ae81ff">2.633e+150</span>   <span style="color:#ae81ff">381.2</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">9</span>   <span style="color:#ae81ff">345.9</span>   <span style="color:#ae81ff">454.8</span>   <span style="color:#ae81ff">8.050e+150</span>   <span style="color:#ae81ff">386.3</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10</span>  <span style="color:#ae81ff">346.6</span>   <span style="color:#ae81ff">467.5</span>   <span style="color:#ae81ff">2.808e+151</span>   <span style="color:#ae81ff">391.4</span>
</span></span></code></pre></div><p>In the next step, we will train the VAR model with selected order (p=3) and use this model to predict the rideshare demand of all 61 taxi zones in the next 48 hours. The prediction results are shown in the figure below. From this figure, we can see that although quite simple, the VAR model can still provide pretty good results for all the taxi zones.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Forecast VAR model using statsmodels</span>
</span></span><span style="display:flex;"><span>model_fitted <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(<span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get the lag order</span>
</span></span><span style="display:flex;"><span>lag_order <span style="color:#f92672">=</span> model_fitted<span style="color:#f92672">.</span>k_ar
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Input data for forecasting</span>
</span></span><span style="display:flex;"><span>forecast_input <span style="color:#f92672">=</span> df_train<span style="color:#f92672">.</span>values[<span style="color:#f92672">-</span>lag_order:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Forecast</span>
</span></span><span style="display:flex;"><span>nobs <span style="color:#f92672">=</span> <span style="color:#ae81ff">48</span>
</span></span><span style="display:flex;"><span>fc <span style="color:#f92672">=</span> model_fitted<span style="color:#f92672">.</span>forecast(y<span style="color:#f92672">=</span>forecast_input, steps<span style="color:#f92672">=</span>nobs)
</span></span><span style="display:flex;"><span>df_forecast <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(fc, index<span style="color:#f92672">=</span>df_test<span style="color:#f92672">.</span>index[:nobs], columns<span style="color:#f92672">=</span>df_test<span style="color:#f92672">.</span>columns <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_VAR&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot of Forecast vs Actuals</span>
</span></span><span style="display:flex;"><span>fig, axes <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(nrows<span style="color:#f92672">=</span>int(len(df_test<span style="color:#f92672">.</span>columns)<span style="color:#f92672">/</span><span style="color:#ae81ff">3</span>), ncols<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">36</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, (col,ax) <span style="color:#f92672">in</span> enumerate(zip(df_test<span style="color:#f92672">.</span>columns, axes<span style="color:#f92672">.</span>flatten())):
</span></span><span style="display:flex;"><span>    df_forecast[col<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;_VAR&#39;</span>]<span style="color:#f92672">.</span>plot(legend<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, ax<span style="color:#f92672">=</span>ax)<span style="color:#f92672">.</span>autoscale(axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;x&#39;</span>,tight<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    df_test[col][:nobs]<span style="color:#f92672">.</span>plot(legend<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, ax<span style="color:#f92672">=</span>ax);
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>set_title(col <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;: Forecast vs Actuals&#34;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>xaxis<span style="color:#f92672">.</span>set_ticks_position(<span style="color:#e6db74">&#39;none&#39;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>yaxis<span style="color:#f92672">.</span>set_ticks_position(<span style="color:#e6db74">&#39;none&#39;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;top&#34;</span>]<span style="color:#f92672">.</span>set_alpha(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tight_layout();
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-26.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-26.png" alt=""> </a></p>
<p>Finally check for Serial Correlation of Residuals (Errors) using Durbin Watson Statistic <a href="https://www.statsmodels.org/dev/generated/statsmodels.stats.stattools.durbin_watson.html">Ref</a>. Here the serial correlation of residuals is used to check if there is any leftover pattern in the residuals (errors). The value of this statistic can vary between 0 and 4. The closer it is to the value 2, then there is no significant serial correlation. The closer to 0, there is a positive serial correlation, and the closer it is to 4 implies negative serial correlation. As shown in the figure below, for all taxi zones the Durbin Watson Statistic is very close to 2, so there is minimal leftover pattern in the residuals.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>out <span style="color:#f92672">=</span> durbin_watson(model_fitted<span style="color:#f92672">.</span>resid)
</span></span><span style="display:flex;"><span>dw <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([pd<span style="color:#f92672">.</span>DataFrame(df<span style="color:#f92672">.</span>columns), pd<span style="color:#f92672">.</span>DataFrame(out)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>dw<span style="color:#f92672">.</span>columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;PULocationID&#39;</span>, <span style="color:#e6db74">&#39;durbin_watson&#39;</span>]
</span></span><span style="display:flex;"><span>fig,ax<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">8</span>))
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>plot(dw<span style="color:#f92672">.</span>PULocationID, dw<span style="color:#f92672">.</span>durbin_watson, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;train_loss&#34;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_ylim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>axhline(<span style="color:#ae81ff">2</span>, color <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;green&#39;</span>, lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>myLocator <span style="color:#f92672">=</span> mticker<span style="color:#f92672">.</span>MultipleLocator(<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>xaxis<span style="color:#f92672">.</span>set_major_locator(myLocator)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Durbin Watson Statistic&#39;</span>)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-27.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-27.png" alt=""> </a></p>
<p>           </p>
<h3 id="54-recurrent-neural-network-rnn">5.4. Recurrent Neural Network (RNN)</h3>
<p>Finally we will use the Recurrent Neural Network (RNN) to predict the rideshare demands of 61 taxi zones simultaneously. To enable a side by side comparison with predictions from VAR model from the previous section, we will use the same test data range as before. On the other hand, since the RNN model does not require stationarity, we will usee all the previous data as training and evaluation set.</p>
<p>As shown in the code block below, the model is quite simple, containing two RNN layers and a full connection layer. The data is standardized first, and we will use last 24 hours of rideshare demand to predict the demand of next hour for each taxi zone.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_mean <span style="color:#f92672">=</span> agg_df_sub_train<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>train_std <span style="color:#f92672">=</span> agg_df_sub_train<span style="color:#f92672">.</span>std()
</span></span><span style="display:flex;"><span>agg_df_sub_train_norm <span style="color:#f92672">=</span> (agg_df_sub_train<span style="color:#f92672">-</span>train_mean)<span style="color:#f92672">/</span>train_std
</span></span><span style="display:flex;"><span>agg_df_sub_val_norm <span style="color:#f92672">=</span> (agg_df_sub_val<span style="color:#f92672">-</span>train_mean)<span style="color:#f92672">/</span>train_std
</span></span><span style="display:flex;"><span>agg_df_sub_test_norm <span style="color:#f92672">=</span> (agg_df_sub_test<span style="color:#f92672">-</span>train_mean)<span style="color:#f92672">/</span>train_std
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">df_to_X_y2</span>(df, window_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>  df_as_np <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>  X <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  y <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(df_as_np)<span style="color:#f92672">-</span>window_size):
</span></span><span style="display:flex;"><span>    row <span style="color:#f92672">=</span> [a <span style="color:#66d9ef">for</span> a <span style="color:#f92672">in</span> df_as_np[i:i<span style="color:#f92672">+</span>window_size]]
</span></span><span style="display:flex;"><span>    X<span style="color:#f92672">.</span>append(row)
</span></span><span style="display:flex;"><span>    label <span style="color:#f92672">=</span> df_as_np[i<span style="color:#f92672">+</span>window_size]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># label = df_as_np[i+window_size][:-4]</span>
</span></span><span style="display:flex;"><span>    y<span style="color:#f92672">.</span>append(label)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(X), np<span style="color:#f92672">.</span>array(y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>WINDOW_SIZE <span style="color:#f92672">=</span> <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>X_train1, y_train1 <span style="color:#f92672">=</span> df_to_X_y2(agg_df_sub_train_norm, WINDOW_SIZE)
</span></span><span style="display:flex;"><span>X_val1, y_val1 <span style="color:#f92672">=</span> df_to_X_y2(agg_df_sub_val_norm, WINDOW_SIZE)
</span></span><span style="display:flex;"><span>X_test1, y_test1 <span style="color:#f92672">=</span> df_to_X_y2(agg_df_sub_test_norm, WINDOW_SIZE)
</span></span><span style="display:flex;"><span>X_train1<span style="color:#f92672">.</span>shape, y_train1<span style="color:#f92672">.</span>shape, X_val1<span style="color:#f92672">.</span>shape, y_val1<span style="color:#f92672">.</span>shape, X_test1<span style="color:#f92672">.</span>shape, y_test1<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>add(InputLayer((<span style="color:#ae81ff">24</span>, <span style="color:#ae81ff">61</span>)))
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>add(SimpleRNN(<span style="color:#ae81ff">40</span>, return_sequences<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>add(SimpleRNN(<span style="color:#ae81ff">40</span>))
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">61</span>, <span style="color:#e6db74">&#39;linear&#39;</span>))
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>summary()
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output</span>
</span></span><span style="display:flex;"><span>Model: <span style="color:#e6db74">&#34;sequential_1&#34;</span>
</span></span><span style="display:flex;"><span>_________________________________________________________________
</span></span><span style="display:flex;"><span> Layer (type)                Output Shape              Param <span style="color:#75715e">#   </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">=================================================================</span>
</span></span><span style="display:flex;"><span> simple_rnn_2 (SimpleRNN)    (<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">24</span>, <span style="color:#ae81ff">40</span>)            <span style="color:#ae81ff">4080</span>      
</span></span><span style="display:flex;"><span> simple_rnn_3 (SimpleRNN)    (<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">40</span>)                <span style="color:#ae81ff">3240</span>      
</span></span><span style="display:flex;"><span> dense_1 (Dense)             (<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">61</span>)                <span style="color:#ae81ff">2501</span>      
</span></span><span style="display:flex;"><span><span style="color:#f92672">=================================================================</span>
</span></span><span style="display:flex;"><span>Total params: <span style="color:#ae81ff">9821</span> (<span style="color:#ae81ff">38.36</span> KB)
</span></span><span style="display:flex;"><span>Trainable params: <span style="color:#ae81ff">9821</span> (<span style="color:#ae81ff">38.36</span> KB)
</span></span><span style="display:flex;"><span>Non<span style="color:#f92672">-</span>trainable params: <span style="color:#ae81ff">0</span> (<span style="color:#ae81ff">0.00</span> Byte)
</span></span></code></pre></div><p>The code block below shows that the model is optimized by Adam algorithm with learning rate set to 0.0001. We trained the model for 1000 epoches, and as can be seen from the figure below, after 1000 epoches, both the training and validation loss are plateaued.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cp1 <span style="color:#f92672">=</span> ModelCheckpoint(<span style="color:#e6db74">&#39;P3_model_1/&#39;</span>, save_best_only<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>model1<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span>MeanSquaredError(), optimizer<span style="color:#f92672">=</span>Adam(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>), metrics<span style="color:#f92672">=</span>[RootMeanSquaredError()])
</span></span><span style="display:flex;"><span>history <span style="color:#f92672">=</span> model1<span style="color:#f92672">.</span>fit(X_train1, y_train1, validation_data<span style="color:#f92672">=</span>(X_val1, y_val1), epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, callbacks<span style="color:#f92672">=</span>[cp1], batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-28.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-28.png" alt=""> </a></p>
<p>The figure below shows the predicted vs actual rideshare demand of each taxi zone for the first 48 hours of test set. This figure has exactly the same time range as the previous section. By comparing these two figures, we can clearly see that RNN produces significantly better prediction than VAR model.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-29.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-29.png" alt=""> </a></p>
<p>To quantify the difference of these two models (VAR and RNN), we have also computed a comprehensive set of metrics, including, Mean Absolute Percentage Error (MAPE), Mean Error (ME), Mean Absolute Error (MAE), Mean Percentage Error (MPE), Root Mean Square Error (RMSE), as well as corr and minmax.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">adjust</span>(val, length<span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>): <span style="color:#66d9ef">return</span> str(val)<span style="color:#f92672">.</span>ljust(length)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forecast_accuracy</span>(forecast, actual):
</span></span><span style="display:flex;"><span>    mape <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(np<span style="color:#f92672">.</span>abs(forecast <span style="color:#f92672">-</span> actual)<span style="color:#f92672">/</span>np<span style="color:#f92672">.</span>abs(actual))  <span style="color:#75715e"># MAPE</span>
</span></span><span style="display:flex;"><span>    me <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(forecast <span style="color:#f92672">-</span> actual)             <span style="color:#75715e"># ME</span>
</span></span><span style="display:flex;"><span>    mae <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(np<span style="color:#f92672">.</span>abs(forecast <span style="color:#f92672">-</span> actual))    <span style="color:#75715e"># MAE</span>
</span></span><span style="display:flex;"><span>    mpe <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean((forecast <span style="color:#f92672">-</span> actual)<span style="color:#f92672">/</span>actual)   <span style="color:#75715e"># MPE</span>
</span></span><span style="display:flex;"><span>    rmse <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean((forecast <span style="color:#f92672">-</span> actual)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">.5</span>  <span style="color:#75715e"># RMSE</span>
</span></span><span style="display:flex;"><span>    corr <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>corrcoef(forecast, actual)[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>]   <span style="color:#75715e"># corr</span>
</span></span><span style="display:flex;"><span>    mins <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>amin(np<span style="color:#f92672">.</span>hstack([forecast[:,<span style="color:#66d9ef">None</span>],
</span></span><span style="display:flex;"><span>                              actual[:,<span style="color:#66d9ef">None</span>]]), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    maxs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>amax(np<span style="color:#f92672">.</span>hstack([forecast[:,<span style="color:#66d9ef">None</span>],
</span></span><span style="display:flex;"><span>                              actual[:,<span style="color:#66d9ef">None</span>]]), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    minmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>mean(mins<span style="color:#f92672">/</span>maxs)             <span style="color:#75715e"># minmax</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>({<span style="color:#e6db74">&#39;mape&#39;</span>:mape, <span style="color:#e6db74">&#39;me&#39;</span>:me, <span style="color:#e6db74">&#39;mae&#39;</span>: mae,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;mpe&#39;</span>: mpe, <span style="color:#e6db74">&#39;rmse&#39;</span>:rmse, <span style="color:#e6db74">&#39;corr&#39;</span>:corr, <span style="color:#e6db74">&#39;minmax&#39;</span>:minmax})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nobs <span style="color:#f92672">=</span> <span style="color:#ae81ff">48</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Forecast Accuracy of: 61&#39;</span>)
</span></span><span style="display:flex;"><span>accuracy_prod <span style="color:#f92672">=</span> forecast_accuracy(test_predictions2[<span style="color:#e6db74">&#39;61_RNN&#39;</span>][:nobs]<span style="color:#f92672">.</span>values, agg_df_sub_test_w24[<span style="color:#e6db74">&#39;61&#39;</span>][:nobs])
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> accuracy_prod<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    print(adjust(k), <span style="color:#e6db74">&#39;: &#39;</span>, round(v,<span style="color:#ae81ff">4</span>))
</span></span></code></pre></div><p>We will use Taxi Zone 61, which is the taxi zone with the highest rideshare demand, as an example, to further examine the performance of RNN model. The table below shows the metrics comparison of VAR vs RNN, and the figure below shows the comparison of RNN prediction vs. Ground Truth for Training set, Validation set, and Test set. From both table and figure, we can clearly see that RNN can capture hourly pattern and weekly pattern, and it has great accuracy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Forecast Accuracy of: <span style="color:#ae81ff">61</span>
</span></span><span style="display:flex;"><span>            VAR         RNN
</span></span><span style="display:flex;"><span><span style="color:#f92672">----------------------------------------</span>
</span></span><span style="display:flex;"><span>mape   :    <span style="color:#ae81ff">0.2715</span>      <span style="color:#ae81ff">0.0918</span>
</span></span><span style="display:flex;"><span>me     :  <span style="color:#f92672">-</span><span style="color:#ae81ff">69.4922</span>      <span style="color:#ae81ff">1.6190</span>
</span></span><span style="display:flex;"><span>mae    :   <span style="color:#ae81ff">79.3486</span>     <span style="color:#ae81ff">24.0960</span>
</span></span><span style="display:flex;"><span>mpe    :   <span style="color:#f92672">-</span><span style="color:#ae81ff">0.2217</span>      <span style="color:#ae81ff">0.0156</span>
</span></span><span style="display:flex;"><span>rmse   :   <span style="color:#ae81ff">99.1222</span>     <span style="color:#ae81ff">31.4320</span>
</span></span><span style="display:flex;"><span>corr   :    <span style="color:#ae81ff">0.8949</span>      <span style="color:#ae81ff">0.9803</span>
</span></span><span style="display:flex;"><span>minmax :    <span style="color:#ae81ff">0.2666</span>      <span style="color:#ae81ff">0.0832</span>
</span></span></code></pre></div><p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-31.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-31.png" alt=""> </a></p>
<p>Finally, the figure below shows the RNN prediction vs. Ground Truth of each taxi zone for the full test data set. From this figure, we can see that RNN indeed has great prediction.</p>
<p><a href="https://andysucao.github.io/Andy_Portfolio/images/projects-3-30.png"><img src="https://andysucao.github.io/Andy_Portfolio/images/projects-3-30.png" alt=""> </a></p>
<p>           
           </p>
<h2 id="6-conclusions">6. Conclusions</h2>
<p>In this post, we have studied the rideshare demands in New York City. First, we conducted EDA and discovered some very interesting patterns within the data. Then we built a clustering model to cluster data and to gain a deeper understanding of how ridesharing is being used. Finally, we developed four machine learning models to predict rideshare utilization, including Seasonal Autoregressive Integrated Moving Average (SARIMA), Gaussian Process (GP), Vector Autoregression (VAR), and Recurrent Neural Network (RNN).</p>
<ul class="pa0">
  
   <li class="list">
     <a href="https://andysucao.github.io/Andy_Portfolio/tags/machine-learning" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Machine Learning</a>
   </li>
  
   <li class="list">
     <a href="https://andysucao.github.io/Andy_Portfolio/tags/time-series-analysis" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Time Series Analysis</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://andysucao.github.io/Andy_Portfolio/post/project-2/">Project 2: Predicitng Customer Churn for a Mobile Phone Carrier</a>
        </li>
	    
	     <li  class="mb2">
          <a href="https://andysucao.github.io/Andy_Portfolio/post/project-1/">Project 1: Predict Real Estate Prices in Beijing</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://andysucao.github.io/Andy_Portfolio/" >
    &copy;  Andy Cao 2024 
  </a>
    <div>







<a href="https://www.linkedin.com/in/cao/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/andysucao" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>






</div>
  </div>
</footer>

    

  <script src="https://andysucao.github.io/Andy_Portfolio/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
